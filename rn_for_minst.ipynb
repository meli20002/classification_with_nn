{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "40f5bb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(layersize):\n",
    "    param={}\n",
    "   \n",
    "\n",
    "    for L in range(1,len(layersize)):\n",
    "        param[f'w{L}']=np.random.randn(layersize[L],layersize[L-1]) * 0.01\n",
    "        param[f'b{L}']=np.zeros((layersize[L],1))\n",
    "    return param "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f487afec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(Z):\n",
    "    expz=np.exp(Z-np.max(Z,axis=0,keepdims=True))\n",
    "    return expz/np.sum(expz,axis=0,keepdims=True)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d667d576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(Z):\n",
    "    return np.maximum(0,Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36f71679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(Z):\n",
    "    return 1/(1+np.exp(-Z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d8860de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(X,param):\n",
    "\n",
    "    L=len(param)//2\n",
    "    activ={\n",
    "        'a0':X\n",
    "    }\n",
    "\n",
    "    for l in range(1,L):\n",
    "        Z=np.dot(param[f'w{l}'] , activ[f'a{l-1}'])+param[f'b{l}']\n",
    "        a=relu(Z)\n",
    "        activ[f'z{l}']=Z\n",
    "        activ[f'a{l}']=a\n",
    "\n",
    "    ZL = np.dot(param[f'w{L}'], activ[f'a{L-1}']) + param[f'b{L}']\n",
    "    activ[f'z{L}'] = ZL  \n",
    "    activ[f'a{L}'] = softmax(ZL) \n",
    "\n",
    "    return activ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "36e7dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_deriv(a):\n",
    "    return (a > 0).astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "23935087",
   "metadata": {},
   "outputs": [],
   "source": [
    "def back_prop(param,activ,Y):\n",
    "    L=len(param)//2\n",
    "    grads={}\n",
    "    m=Y.shape[1]\n",
    "    dz=activ[f'a{L}']-Y\n",
    "    grads[f'dz{L}'] = dz\n",
    "    grads[f'dw{L}']=1/m* np.dot(dz,activ[f'a{L-1}'].T)\n",
    "    grads[f\"db{L}\"] = (1 / m) * np.sum(dz, axis=1, keepdims=True)\n",
    "    for l in reversed(range(1,L)):\n",
    "        w_next=param[f'w{l+1}']\n",
    "        dz_next=grads[f'dz{l+1}']\n",
    "\n",
    "        grads[f'dz{l}']=np.dot(w_next.T,dz_next)*relu_deriv(activ[f'a{l}']) #activ[f'a{l}']*(1-activ[f'a{l}']) derivative of the sigmoid s(x)*(1-S(x))\n",
    "        grads[f'dw{l}']=(1/m)*np.dot(grads[f'dz{l}'],activ[f'a{l-1}'].T)\n",
    "        grads[f'db{l}']=(1/m)*np.sum(grads[f'dz{l}'],axis=1,keepdims=True)\n",
    "    return grads \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324eb6a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "0e211bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def update(para,gradients,lr):\n",
    "    L=len(para)//2\n",
    "    for l in range(1,L+1):\n",
    "        para[f'w{l}']-=lr*gradients[f'dw{l}'] \n",
    "        para[f'b{l}']-=lr*gradients[f'db{l}']\n",
    "    return para"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "692e8058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(X,para):\n",
    "    activ=forward(X,para)\n",
    "    L=len(para)//2\n",
    "    return np.argmax(activ[f'a{L}'],axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99b4d884",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    return -np.sum(Y * np.log(AL + 1e-8)) / m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b4225f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(X,Y,sizes,lr=0.01,iter=2000):\n",
    "     param=init(sizes)\n",
    "     cost=[]\n",
    "    \n",
    "     for i in range(iter):\n",
    "           \n",
    "            activ=forward(X,param)\n",
    "\n",
    "            err=loss(activ[f'a{len(sizes)-1}'], Y)\n",
    "            grads=back_prop(param,activ,Y)\n",
    "            cost.append(err)\n",
    "            param=update(param,grads,lr)\n",
    "            if i % 100 == 0:\n",
    "                print(f\"Epoch {i}, Loss: {loss(activ[f'a{len(sizes)-1}'], Y)}\")\n",
    "     return param      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a307bd40",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def one_hot(Y, num_classes):\n",
    "    one_hot_Y = np.zeros((num_classes, Y.size))\n",
    "    one_hot_Y[Y, np.arange(Y.size)] = 1\n",
    "    return one_hot_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "e29b4e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.3025836309234635\n",
      "Epoch 100, Loss: 2.299350361046551\n",
      "Epoch 200, Loss: 2.2959369220376296\n",
      "Epoch 300, Loss: 2.235430173373301\n",
      "Epoch 400, Loss: 1.1004974958026725\n",
      "Epoch 500, Loss: 0.6404244586535693\n",
      "Epoch 600, Loss: 0.539512780370786\n",
      "Epoch 700, Loss: 0.49160049240515347\n",
      "Epoch 800, Loss: 0.4207098474950601\n",
      "Epoch 900, Loss: 0.3591931326015907\n",
      "Epoch 1000, Loss: 0.31163970206496483\n",
      "Epoch 1100, Loss: 0.2748252213140955\n",
      "Epoch 1200, Loss: 0.24376417063099828\n",
      "Epoch 1300, Loss: 0.21634247455359154\n",
      "Epoch 1400, Loss: 0.19166586965703034\n",
      "Epoch 1500, Loss: 0.16932487357602635\n",
      "Epoch 1600, Loss: 0.1493122449614927\n",
      "Epoch 1700, Loss: 0.13131194284887307\n",
      "Epoch 1800, Loss: 0.11532817045133345\n",
      "Epoch 1900, Loss: 0.10103691094621813\n",
      "Epoch 2000, Loss: 0.08821236262065377\n",
      "Epoch 2100, Loss: 0.07687046712592581\n",
      "Epoch 2200, Loss: 0.0669180259810258\n",
      "Epoch 2300, Loss: 0.05834822051261104\n",
      "Epoch 2400, Loss: 0.051030301940082325\n",
      "Epoch 2500, Loss: 0.04478330131961429\n",
      "Epoch 2600, Loss: 0.03940656553715944\n",
      "Epoch 2700, Loss: 0.03475283337866888\n",
      "Epoch 2800, Loss: 0.030735809028828123\n",
      "Epoch 2900, Loss: 0.027261851212844527\n",
      "Epoch 3000, Loss: 0.024244692230893712\n",
      "Epoch 3100, Loss: 0.02161851761611875\n",
      "Epoch 3200, Loss: 0.019329368146296\n",
      "Epoch 3300, Loss: 0.017342750426575675\n",
      "Epoch 3400, Loss: 0.015632009807134712\n",
      "Epoch 3500, Loss: 0.014156848131092229\n",
      "Epoch 3600, Loss: 0.012883119434067837\n",
      "Epoch 3700, Loss: 0.011777833376562446\n",
      "Epoch 3800, Loss: 0.010813319956953735\n",
      "Epoch 3900, Loss: 0.009968058651885032\n",
      "Epoch 4000, Loss: 0.009222666677004464\n",
      "Epoch 4100, Loss: 0.008561315517036556\n",
      "Epoch 4200, Loss: 0.007973628759778006\n",
      "Epoch 4300, Loss: 0.007447708395764025\n",
      "Epoch 4400, Loss: 0.006975994128795815\n",
      "Epoch 4500, Loss: 0.00655120019238792\n",
      "Epoch 4600, Loss: 0.006166641949820099\n",
      "Epoch 4700, Loss: 0.005817983753951101\n",
      "Epoch 4800, Loss: 0.005500554205188754\n",
      "Epoch 4900, Loss: 0.005210581152786406\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# Load MNIST dataset\n",
    "X, y = fetch_openml('mnist_784', version=1, return_X_y=True)\n",
    "\n",
    "# Normalize the data\n",
    "X = X / 255.0  # Convert X to numpy and normalize\n",
    "\n",
    "\n",
    "# Convert labels to integers and apply one-hot encoding\n",
    "y = y.astype(int)\n",
    "\n",
    "Y = one_hot(y.to_numpy(), 10)  # Apply one-hot encoding\n",
    "\n",
    "# Train the model using first 1000 samples\n",
    "parameters = train(X[:5000].T, Y[:, :5000], sizes=[784, 128, 64, 10], lr=0.1,iter=5000)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "49256af0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 95.00%\n"
     ]
    }
   ],
   "source": [
    "outputs = forward(X[6000:6100].T, parameters)['a' + str(len(parameters)//2)]\n",
    "preds = np.argmax(outputs, axis=0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = np.mean(preds == y[6000:6100]) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3184bc05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "8d47aa04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:32: SyntaxWarning: invalid escape sequence '\\i'\n",
      "<>:32: SyntaxWarning: invalid escape sequence '\\i'\n",
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_7580\\1000900171.py:32: SyntaxWarning: invalid escape sequence '\\i'\n",
      "  img_vector = preprocess_image('images\\im3.jpeg')\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted digit: [3]\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_image(path):\n",
    "  \n",
    "    img = Image.open(path).convert('L')  \n",
    "\n",
    "    # Resize to 28x28\n",
    "    img = img.resize((28, 28))\n",
    "     \n",
    "  \n",
    "    img_array = np.array(img)\n",
    "\n",
    "\n",
    "    plt.imshow(img_array, cmap='gray')\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "\n",
    "    if img_array.mean() > 127:  \n",
    "        img_array = 255 - img_array \n",
    "\n",
    "    # Normalize pixel values\n",
    "    img_array = img_array / 255.0\n",
    "\n",
    "    img_vector = img_array.reshape(784, 1)\n",
    "\n",
    "    return img_vector\n",
    "\n",
    "\n",
    "img_vector = preprocess_image('images\\im3.jpeg')\n",
    "pred = predict(img_vector, parameters)\n",
    "print(f\"Predicted digit: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3c10266f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"model.pkl\", \"wb\") as file:\n",
    "    pickle.dump(parameters, file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
